[![Build Status](https://travis-ci.org/GL-Li/totalcensus.svg?branch=master)](https://travis-ci.org/GL-Li/totalcensus)

# Extract data from decennial census and ACS summary files

This package provides total solutions to extracts any data from the raw summary files of decennial census and American Community Survey (ACS) and returns a tidy data.table. The extracted data can be easily processed with `data.table` or `dplyr` packages. 


## Why another R census package

The [census API](https://www.census.gov/data/developers/guidance/api-user-guide.Available_Data.html) offers most data in decennial census and ACS data for download and API-based packages such as `tidycensus`, `censusapi` and `acs` make the downloading very easy in R. So why we need another package?

In one sentence, package `totalcensus` makes census data extraction easier and gives you full access and control of all census data downloaded to you own computer.

As an extreme example, here is how we extract the median home values in **all** block groups in the United States from 2011-2015 ACS 5-year survey with this package. You simply need to call the function `read_acs5year()` and provide parameters. It takes 15 seconds for my 4-years old laptop to return the data of all 217,739 block groups. In addition to the table contents we request, we also get the population and coordinate of each block group.

```{r eval = FALSE}
library(totalcensus)
library(data.table)
library(magrittr)
home_national <- read_acs5year(
    year = 2015,
    states = states_DC,   # all 50 states plus DC
    table_contents = "home_value = B25077_001",
    summary_level = "block group"
)
```

With the coordinates, we can visualize the data on US map with `ggplot2` and `ggmap`. Each data point in the figure below corresponds to a a block group, colored by median home value and sized by population. This plot not only displays the median home values, but also tells population densities on the map.

![](figures/home_value_national_blockgroup.png)

There are additional benefits of using this package:

- You can get detailed urban/rural data from Census 2010. This package use summary file 1 with urban/rural update, while the census API only provide data in summary file 1 before urban/rural update. 
- You can get all block groups that belong or partially belong to a city. Original census data do not specify city information for a block group as a block group may not uniquely belong to a city. However, large cities have most block groups within their boundaries and only a small number of block groups run across the borders. The block group level data provide valuable spatial information of a city. This is particularly helpful for ACS 5-year surveys which cover data down to the level of block groups. 
- It provides longitude and latitude of the internal point of a geographic area for easy and quick mapping. You do not always need shape files to make nice maps, as the map shown above. 




## Installation

```{r eval = FALSE}
install.packages("devtools")

devtools::install_github("GL-Li/totalcensus")
```

## Preparation before using the package

This package requires downloading census data to your local computer. You need about 200 GB free disc space to download summary files of most recent decennial Census, most recent ACS 5-year survey, and most recent ACS 1-year surveys. Then we need to generate helper data from Census 2010 to be used to improve ACS data. Do not worry we have functions to facilitate all the tasks. Just follow the steps below.

**Step 1**: create a folder to store downloaded data. Let's named it as `my_census_data`. The full path to this folder is `xxxxx/my_census_data`, replacing `xxxxx` with the actual path. Then run the function below to set the path for the package.

```{r eval = FALSE}
set_path_to_census("xxxxx/my_census_data", install = TRUE)
```

**Step 2**: download and extract census data. By default, the function `download_census()` downloads Census 2010, 2011-2015 ACS 5-year survey, and 2014, 2015, and 2016 ACS 1-year surveys. You need 200 GB disc space for the default downloading. The Census 2010 alone takes about 140 GB.  You can choose which dataset to download if you do not need the default ones. Re-run the function to repair possible mistakes during downloading and extraction.

```{r eval = FALSE}
# download the default datasets
download_census()

# download selected dataset, for example, 2015 ACS 5-year survey
download_census(survey = "acs5year", year = 2015)
```

The downloaded data will also be extracted automatically to the folder `my_census_data`. It takes a long time to download and extract. You can stop downloading any time and then resume downloading by running the function again. 

The data can be found on Census Bureau's website but you do not need to download them manually. 

- [Census 2010 summary file 1 with urban/rural update](https://www2.census.gov/census_2010/04-Summary_File_1/Urban_Rural_Update/)
- [ACS summary files since 2005](https://www2.census.gov/programs-surveys/acs/summary_file/)


**Step 3**: generate data from Census 2010
The generated data will provide more details to ACS 1-year and 5-year survey data. If you already downloaded Census 2010 data, you can generate data by running:

```{r eval = FALSE}
generate_census_data()
```

If you do not have Census 2010 data, you can download the generated data by running:
```{r, eval = FALSE}
download_generated_data()
```



## Basic application
The package has three functions to read decennial census, ACS 5-year survey, and ACS 1-year survey: `read_decennial()`, `read_acs5year()`, and `read_acs1year()`. They are similar but as these  datasets are so different, we prefer to keep three separate functions, one for each. 

The function arguments serve as filters to select the data you want:

- year: the year or ending year of the data you must provide.
- states: the states of which you want read the geography and data files. There are 50 states, "DC" and "PR" (Peuter Rico), plus a special one "US" for national files. You must specify this parameter.
- table_contents: this parameter specifies which table contents you want to read. Population is always returned even if table_contents is NULL. Users can name the table contents in the format such as c("male = B01001_002", "female = B01001_026"). 
- areas: if you know which metropolitan areas, counties, cities and towns you want to get data from, you can specify them here by name or FIPS code, for example, c("New York metro", "PLACE = UT62360", "Salt Lake City city, UT").
- geo_headers: In case you do not know which areas to extract data, you can read all the geographic headers specified here and select areas after reading. 
- summary_level: it determines which level of data to extract. Common ones like "state", "county", "place", "county subdivision", "tract", "block group", and "block" can be input as plain text. Others have to be given by code.
- geo_comp: specifies data of which geographic component you want. Most common ones are "all", "urban", and "rural".

There are also a family of `search_xxx()` functions to help find table contents, geoheaders, summary levels, geocomponents, FIPS codes and CBSA codes.

The following examples demonstrate how to use these read and search functions.

### Median gross rent in cities with population over 65000
A renting company wants to know the most recent rents in major cities in the US. How to get the data?

We first need to determine which survey to read. For most recent survey data, we want to read 2016 ACS 1-year surveys, which provide data for geographic areas of population over 65000.

We also need to determine which data files to read by running `search_summarylevels("acs")`. Cities are at the summary level of "160", which is only in state files of 2016 ACS 1-year survey. So we have to read each of the states. We have dataset `states_DC` which is a vector of 50 states and DC.

Then we need to check if 2016 ACS 1-year survey has the rent data. We run `search_tablecontents("acs")` to open the dataset with `View()` in RStudio. You can provide keywords for search in the function but it is better to do the search in RStudio with filters. There are so many tables that contains string "rent". It takes some time to find the right one if you are not familiar with ACS tables. After some struggle, we think  B25064_001 is what we want.

We do not need to specify `areas` and `geo_headers` as we are extracting all geographic areas matches the conditions.

Here is the code that gives what we want.
```{r eval = FALSE}
rent <- read_acs1year(
    year = 2016,
    states = states_DC,
    table_contents = "rent = B25064_001",
    summary_level = "place",
    geo_comp = "all"
) 

# Fisrt 5 rows
  #             GEOID        lon      lat state population rent GEOCOMP SUMLEV                                  NAME
  # 1: 16000US1150000  -77.01709 38.90415    DC     681170 1376     all    160 Washington city, District of Columbia
  # 2: 16000US2829700  -89.07184 30.41606    MS      72077  774     all    160            Gulfport city, Mississippi
  # 3: 16000US2836000  -90.21282 32.31583    MS     169141  813     all    160             Jackson city, Mississippi
  # 4: 16000US2205000  -91.12590 30.44845    LA     227707  818     all    160           Baton Rouge city, Louisiana
  # 5: 16000US2208920  -93.65559 32.52366    LA      68485  959     all    160          Bossier City city, Louisiana
```

It is always nice to visualize them on a map.
```{r eval = FALSE}
library(ggplot2)
library(ggmap)
us_map <- get_map("united states", zoom = 4, color = "bw")

ggmap(us_map) + 
    geom_point(
        data = rent[order(-population)],
        aes(lon, lat, size = population/1e3, color = rent)
    ) +
    ylim(25, 50) +
    scale_size_area(breaks = c(100, 200, 500, 1000, 2000, 5000)) +
    scale_color_continuous(low = "green", high = "red") +
    labs(
        color = "monthly\nrent ($)",
        size = "total\npopulation\n(thousand)",
        title = "Monthly rent in cities over 65000 population",
        caption = "Source: 2016 ACS 1-year survey"
    ) +
    theme(
        panel.background = element_blank(),
        axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        title = element_text(size = 14)
    )
```
![](figures/rent_cities_population_over_65000.png)



### Black communities in South Bend city, IN at block level
Only the decennial census has data down to block level. The most recent one is Census 2010. We will use two method to extract the data.

#### Method 1: using argument `areas`

Knowing names of a city, county, metro area, or town, we can feed them directly to argument `areas`. The returned data.table contains the table contents we want to read as well as population and coordinates. The reading takes a few seconds.

```{r eval = FALSE}
# read data of black population in each block
black_popul <- read_decennial(
    year = 2010,
    states = "IN",
    table_contents = "black_popul = P0030003",
    areas = "South Bend city, IN",
    summary_level = "block"
)

# first 5 rows of black_popul:
   #                   area       lon      lat state population black_popul GEOCOMP SUMLEV
   # 1: South Bend city, IN -86.21864 41.63613    IN         28          10     all    100
   # 2: South Bend city, IN -86.21659 41.63670    IN          0           0     all    100
   # 3: South Bend city, IN -86.22172 41.63573    IN         52          16     all    100
   # 4: South Bend city, IN -86.22022 41.63182    IN        279          21     all    100
   # 5: South Bend city, IN -86.22093 41.63367    IN         42           1     all    100
```

It is better to separate data manipulation from reading to save reading time as you usually need to try multiple manipulation. Data manipulation can be done with `data.table` or `dplyr`.

```{r eval = FALSE}
# remove blocks where no people lives in and add a column of black percentage. 
black <- black_popul %>%
    .[population != 0] %>%
    # percentage of black population in each block
    .[, black_pct := round(100 * black_popul / population, 2)]
```


### Method 2: use argument `geo_headers`
Argument `geo_headers` works for any geographic areas presented in census geography files, such as American Indian Area/Alaska Native Area/ Hawaiian Home Land and congressional district, which are not covered by argument `areas`. 

Here is how we read black population in each block in South Bend city, using `geo_headers`. A city is a census place with geographic header "PLACE". We first read all data for all "PLACE":
```{r eval = FALSE}
black_popul_place <- read_decennial(
    year = 2010,
    states = "IN",
    table_contents = "black_popul = P0030003",  
    geo_headers = "PLACE",
    summary_level = "block"
)
```

We can then select rows of South Bend by the area name or by PLACE code, which can be search with `search_fips()`.
```{r eval = FALSE}
# select by name
black_popul <- black_popul_place[area %like% "South Bend"]

# select by code
black_popul <- black_popul_place[PLACE == "71000"]
```


### Visualize the data
Again we visualize on map with `ggplot2` and `ggmap`.
```{r eval = FALSE}
south_bend <- get_map("south bend, IN", zoom = 13, color = "bw")
ggmap(south_bend) +
    geom_point(
        data = black,
        aes(lon, lat, size = population, color = black_pct)
    ) +
    scale_size_area(breaks = c(10, 100, 200, 500)) +
    scale_color_continuous(low = "green", high = "red") +
    labs(
        color = "% black",
        size = "total\npopulation",
        title = "Black communities in South Bend city at block level",
        caption = "Source: Census 2010"
    ) +
    theme(
        panel.background = element_blank(),
        axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        title = element_text(size = 14)
    )
```

![](figures/south_bend_block_black.png)

